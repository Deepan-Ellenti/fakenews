{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c838a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # to search for words from an extract\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # to find unnecessary words\n",
    "from nltk.stem.porter import PorterStemmer #to perform stemming that finds the root word of each word\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer#helps to deal with most frequent words and measures how often a word occurs in the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d260c97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download all the stopwords from the nltk library\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a111b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# View the English stopwords that will be unnecessary for our analysis\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5b2529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and viewing first 5 rows\n",
    "\n",
    "dataframe = pd.read_csv(r\"C:\\Users\\avata\\Desktop\\Fake News Project\\train.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa1ca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape # the dataset contains 20800 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da574ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#  general information about the dataset\n",
    "\n",
    "dataframe.info() # we understand that there are a number of null values in certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b90bda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for number of null values in each column\n",
    "dataframe.isna().sum() # we have null values for 'title', 'author', and 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c56c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling null values with empty space\n",
    "\n",
    "dataframe = dataframe.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56b160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the 'id' column as it is not significant for further analysis\n",
    "dataframe.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf29f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        1957\n",
       "Pam Key                                  243\n",
       "admin                                    193\n",
       "Jerome Hudson                            166\n",
       "Charlie Spiering                         141\n",
       "                                        ... \n",
       "David E. Sanger and Rick Gladstone         1\n",
       "Nathaniel Popper and Michael Corkery       1\n",
       "SloMoe                                     1\n",
       "Neil MacFarquhar and David E. Sanger       1\n",
       "WB                                         1\n",
       "Name: author, Length: 4202, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[\"author\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5775d6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4202"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe[\"author\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3e18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 4202 authors in the dataset and highest number of articles belong to Pam Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e72480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dependent(Y) and independent(X) variables\n",
    "\n",
    "x = dataframe['text']\n",
    "y = dataframe['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782f243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c4614e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvect = TfidfVectorizer(stop_words='english',max_df=0.7)\n",
    "tfid_x_train = tfvect.fit_transform(x_train)\n",
    "tfid_x_test = tfvect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b0ac9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Logistic Regression Model\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Fit & Train the model\n",
    "classifier.fit(tfid_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b868d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.47%\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(tfid_x_test)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print(f'Test Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9bbf2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.4%\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = classifier.predict(tfid_x_train)\n",
    "score = accuracy_score(y_train,y_pred1)\n",
    "print(f'Train Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b329cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2010  104]\n",
      " [ 126 1920]]\n"
     ]
    }
   ],
   "source": [
    "cf = confusion_matrix(y_test,y_pred, labels=[1,0])\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ada50e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_news_det(news):\n",
    "    input_data = [news]\n",
    "    vectorized_input_data = tfvect.transform(input_data)\n",
    "    prediction = classifier.predict(vectorized_input_data)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6011b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "fake_news_det('I love all women, except for the fat ones, the ugly ones and the feminists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa7586cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "fake_news_det('Hillary Clinton spent a whole afternoon drunk and unresponsive while her campaign staff tried to reach her, a new WikiLeaks email reveals. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afab55c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "fake_news_det('Just days before the anniversary of Roe v. Wade, Pope Francis has sent a message of support to the March for Life taking place in Paris, France, on Sunday. [â€œThe Church must never tire of being an advocate for life and must not neglect to proclaim that human life is to be protected unconditionally from the moment of conception until natural death,â€ the Popeâ€™s message said.  Pope Francis has been a vocal critic of the abortion industry, comparing it to King Herodâ€™s slaughter of the innocents at the time of Jesus, and accusing the abortion lobby of working with a   mentality that seeks to eliminate those who get in oneâ€™s way. In his message to   marchers, Francis expressed his solidarity with their efforts and urged them to continue to proclaim the value of human life. â€œBeyond this legitimate manifestation in defense of human life, the Holy Father encourages participants in the March for Life to work tirelessly for the building of a civilization of love and a culture of life,â€ said the message, which was sent through the Apostolic Nuncio to France, Archbishop Luigi Ventura. On Sunday, President Trump is expected to sign an executive order cutting funding to the International Planned Parenthood Foundation, in a restoration of Ronald Reaganâ€™s â€œMexico City policyâ€ that banned U. S. government funding of abortion around the world. The executive order would reportedly be timed to coincide with the anniversary of the 1973 Roe v. Wade Supreme Court decision that legalized    on all 50 states in the Union. Follow Thomas D. Williams on Twitter Follow @tdwilliamsrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c36d2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(classifier,open('model.pkl', 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d0cd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_news_det1(news):\n",
    "    input_data = [news]\n",
    "    vectorized_input_data = tfvect.transform(input_data)\n",
    "    prediction = loaded_model.predict(vectorized_input_data)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e122fa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "fake_news_det1('This article is part of a series aimed at helping you navigate lifeâ€™s opportunities and challenges. What else should we write about? Contact us:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff90dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
